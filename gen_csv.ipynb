{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "datadir = os.path.join(os.environ['USERPROFILE'],'OneDrive - Colorado School of Mines/Research/MIDDMI/TCO/Data')\n",
    "indir = os.path.join(datadir,'in') #libraries to be processed\n",
    "outdir = os.path.join(datadir,'out') #output directory for csvs and logs\n",
    "procdir = os.path.join(datadir,'processed') #destination dir for processed libraries\n",
    "config = os.path.join(datadir,'config') #config/parameter file location\n",
    "\n",
    "############################\n",
    "\"read config files\"\n",
    "############################\n",
    "os.chdir(config)\n",
    "\n",
    "#load variable definitions\n",
    "#----------------------------\n",
    "vardictdf = pd.read_excel('VariableDict.xlsx')\n",
    "\n",
    "#put standard variables into dict\n",
    "stdvardf = vardictdf[vardictdf.Keyword.str[0] != '!']\n",
    "stdvars = list(stdvardf.VarName)\n",
    "headers = list(stdvardf.Keyword + ': ' + stdvardf.DisplayName)\n",
    "stdvardict = dict(zip(stdvars,headers))\n",
    "\n",
    "#composition variables\n",
    "compvardf = vardictdf[vardictdf.Keyword == '!composition']\n",
    "compvars = list(compvardf.VarName)\n",
    "\n",
    "#load PLD parameters\n",
    "#----------------------------\n",
    "prepstep = 'Pulsed Laser Deposition'\n",
    "params = pd.read_excel('PLD_params.xlsx',skiprows=3,index_col=0)\n",
    "paramdictdf = pd.read_excel('PLD_ParamDict.xlsx')\n",
    "#put standard params into dict\n",
    "stdparamdf = paramdictdf[paramdictdf.Keyword.str[0] != '!']\n",
    "stdparams = list(stdparamdf.ParamName)\n",
    "parheaders = list(stdparamdf.Keyword + ': ' + stdparamdf.DisplayName)\n",
    "stdparamdict = dict(zip(stdparams,parheaders))\n",
    "params = params.rename(index=str, columns = stdparamdict) #rename headers to ingestable format using paramdict\n",
    "params.insert(1,'PREPARATION STEP NAME',prepstep)\n",
    "#end config\n",
    "\n",
    "#library prefix to strip out\n",
    "libprefix = 'PDAC_COM3_'\n",
    "\n",
    "########################################\n",
    "\"loop through all libraries in indir\"\n",
    "########################################\n",
    "os.chdir(indir)\n",
    "\n",
    "for lib in next(os.walk(indir))[1]:\n",
    "    os.chdir(lib)\n",
    "    \n",
    "    #log file\n",
    "    logname = lib + '_gen_csv.log'\n",
    "    log = open(logname, 'w')\n",
    "    log.write('Processing library ' + lib + '\\n')\n",
    "    csvname = lib + '_AllVar.csv'\n",
    "    \n",
    "    all_var = pd.DataFrame([])\n",
    "    \n",
    "    #read the Points file to determine file length\n",
    "    pts = pd.read_csv(lib + '_Points.txt',sep='\\t',usecols = [0]) \n",
    "    \n",
    "    #dataframes to store composition data\n",
    "    chm = pd.DataFrame()#np.zeros((len(pts),1),dtype='str'),columns=['formula'])\n",
    "    sitesum = pd.DataFrame(np.zeros((len(pts),2)), columns = ['A','B'])\n",
    "    \n",
    "    #track found variables\n",
    "    foundvars = ['Point','Row','Column']\n",
    "    \n",
    "    for fname in glob.glob(lib + '*.txt'):\n",
    "        vname = fname[len(lib)+1:fname.find('.txt')]\n",
    "        #regular variables\n",
    "        if vname in stdvars:\n",
    "            if len(all_var) == 0:\n",
    "                cols = None\n",
    "            else:\n",
    "                cols = [3]\n",
    "            df = pd.read_csv(fname,sep='\\t',usecols = cols)\n",
    "            all_var = pd.concat([all_var,df], axis=1)\n",
    "        #composition variables\n",
    "        elif vname in compvars:\n",
    "            dfc = pd.read_csv(fname,sep='\\t',usecols = [3])\n",
    "            elmnt = vname[:vname.find('_at')]\n",
    "            chm[elmnt] = dfc[vname] \n",
    "            sitesum.A = sitesum.A + dfc[vname]\n",
    "        \n",
    "        foundvars.append(vname)\n",
    "    \n",
    "    #identify ignored and missing variables\n",
    "    ignoredvars = np.setdiff1d(foundvars,stdvars+compvars, assume_unique=True)\n",
    "    missingstd = np.setdiff1d(stdvars,foundvars, assume_unique=True)\n",
    "    missingcomp = np.setdiff1d(compvars,foundvars, assume_unique=True)\n",
    "    log.write('Ignored variables:\\n\\t' + '\\n\\t'.join(ignoredvars) + '\\n')\n",
    "    log.write('*Warning: missing standard variables:\\n\\t' + '\\n\\t'.join(missingstd) + '\\n')\n",
    "    log.write('*Warning: missing composition variables:\\n\\t' + '\\n\\t'.join(missingcomp) + '\\n')\n",
    "        \n",
    "    #determine composition\n",
    "    sitesum.B = 1 - sitesum.A\n",
    "    sitemax = sitesum.max(axis=1)\n",
    "    sitenorm = sitesum.divide(sitemax,axis=0) #normalize for the higher occupancy site\n",
    "    chmnorm = chm.divide(sitemax,axis=0)\n",
    "    chmnorm.insert(0,'Ba',list(sitenorm.B))\n",
    "    chmnorm = chmnorm.round(5)\n",
    "    for elmnt in list(chmnorm.columns):\n",
    "        chmnorm[elmnt] = elmnt + chmnorm[elmnt].map(str) \n",
    "    chmnorm['formula'] = chmnorm.apply(lambda x: ''.join(x),axis=1)\n",
    "    chmnorm['formula'] = chmnorm['formula'] + 'O3'\n",
    "\n",
    "    sample = lib[len(libprefix):]\n",
    "\n",
    "    all_var = all_var.rename(index=str, columns = stdvardict) #rename headers to ingestable format using vardict\n",
    "    all_var.insert(0,'IDENTIFIER: Sample number',sample) #add sample column        \n",
    "    all_var.insert(0,'FORMULA',list(chmnorm['formula'])) #add formula column\n",
    "    \n",
    "    #add PLD parameters corresponding to sample number\n",
    "    if sample in list(params.index):\n",
    "        all_var = all_var.join(params,on='IDENTIFIER: Sample number')\n",
    "    else:\n",
    "        log.write('*Warning: could not locate PLD parameters\\n')\n",
    "    \n",
    "    all_var.to_csv(csvname,index=False)\n",
    "    log.write('Wrote ' + csvname + '\\n')\n",
    "    \n",
    "    #move processed library to procdir\n",
    "    log.write('Finished processing library ' + lib)\n",
    "    log.close()\n",
    "    \n",
    "    #copy csv and log to outdir\n",
    "    copyfile(csvname, os.path.join(outdir,csvname))\n",
    "    copyfile(logname, os.path.join(outdir,logname))\n",
    "    os.chdir('..')\n",
    "    os.rename(os.path.join(indir,lib), os.path.join(procdir,lib))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jdhuang'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['USERPROFILE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
